import sys
import locale
sys.getdefaultencoding = lambda: "utf-8"
locale.getpreferredencoding = lambda: "utf-8"

import streamlit as st
import os
import datetime
import sqlite3
import pandas as pd
import matplotlib.pyplot as plt
from io import BytesIO
from utils.parse_pdf import extract_text_from_file
from utils.extract_llm import extract_fields
from utils.db_ops import insert_or_update_drug, init_db
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

# åˆå§‹åŒ–
UPLOAD_DIR = "data/uploads"
DB_PATH = "data/drugs.db"
GOOGLE_SHEET_CSV = "https://docs.google.com/spreadsheets/d/1EXKqsz1nYaubjNJpUPy73nyvT9uaNRhutMXMDEjvsk4/export?format=csv"

st.set_page_config(page_title="Drug Trial Extractor", layout="wide")
st.title("ğŸ§¬ è¯ç‰©ä¸´åºŠè¯•éªŒä¿¡æ¯æå–å·¥å…·")

# åˆå§‹åŒ–æ•°æ®åº“
init_db(DB_PATH)

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ä¸Šä¼  PDF æˆ– TXT æ–‡ä»¶", type=["pdf", "txt"])

if uploaded_file:
    os.makedirs(UPLOAD_DIR, exist_ok=True)
    file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.read())

    st.success(f"âœ… æ–‡ä»¶å·²ä¿å­˜ï¼š{uploaded_file.name}")
    text = extract_text_from_file(file_path)
    trial_data = extract_fields(text)
    trial_data["source_file"] = uploaded_file.name
    trial_data["update_time"] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    st.subheader("ğŸ” æå–ç»“æœ")
    st.json(trial_data)
    insert_or_update_drug(trial_data, DB_PATH)
    st.success("âœ… æ•°æ®å·²ä¿å­˜ï¼ˆè‡ªåŠ¨åˆ›å»ºæˆ–æ›´æ–°ï¼‰")

# æ•°æ®å¯¼å‡º
st.markdown("---")
st.subheader("ğŸ“¤ å¯¼å‡ºæ•°æ®")
if st.button("å¯¼å‡ºä¸º CSV"):
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query("SELECT * FROM trial_data", conn)
    conn.close()
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button("ğŸ“¥ ç‚¹å‡»ä¸‹è½½ CSV", csv, "trial_data_export.csv", "text/csv")

# Google Sheet è¯ç‰©åŒ¹é…åŠŸèƒ½
st.markdown("---")
st.subheader("ğŸ” æŸ¥æ‰¾æœ€ç›¸ä¼¼è¯ç‰©ä¿¡æ¯ï¼ˆæ¥è‡ª Google Sheetï¼‰")

query = st.text_input("è¯·è¾“å…¥è¯ç‰©åï¼ˆç”¨äºæŸ¥æ‰¾æœ€ç›¸ä¼¼çš„ Modality & Indicationï¼‰")

if query:
    try:
        df_sheet = pd.read_csv(GOOGLE_SHEET_CSV)
        df_sheet = df_sheet.dropna(subset=["Modality (ADC / CAR-T / TCE)", "Indication"])
        df_sheet["combined"] = df_sheet["Modality (ADC / CAR-T / TCE)"].astype(str) + " " + df_sheet["Indication"].astype(str)
        
        # ç›¸ä¼¼åº¦åŒ¹é…
        corpus = df_sheet["combined"].tolist()
        corpus.append(query)
        vectorizer = TfidfVectorizer().fit_transform(corpus)
        similarity = cosine_similarity(vectorizer[-1], vectorizer[:-1])
        most_similar_index = similarity.argmax()
        best_match_row = df_sheet.iloc[[most_similar_index]]
        
        st.markdown("### ğŸ“Œ æœ€ç›¸ä¼¼çš„è¯ç‰©ä¿¡æ¯å¦‚ä¸‹ï¼š")
        st.dataframe(best_match_row)

        # æå–æ—¶é—´åˆ—ç»˜å›¾
        timeline_cols = [
            "FIH â†’ Pivotal Start",
            "Accelerated Approval Trial Enrollment Duration",
            "Full Approval Trial Enrollment Duration",
            "Accelerated Approval Trial Topline Lag",
            "Full Approval Trial Topline Lag"
        ]
        timeline_values = []
        for col in timeline_cols:
            val = best_match_row[col].values[0]
            try:
                val = float(val)
                timeline_values.append(val)
            except:
                timeline_values.append(0.0)

        fig, ax = plt.subplots(figsize=(10, 4))
        bars = ax.barh(timeline_cols, timeline_values, color="orange")
        for bar in bars:
            width = bar.get_width()
            ax.text(width + 0.5, bar.get_y() + bar.get_height() / 2, f"{width:.2f}", va='center')
        ax.set_xlabel("æ—¶é—´ï¼ˆæœˆï¼‰")
        ax.set_title("è¯ç‰©ä¸´åºŠè¯•éªŒä¸»è¦é˜¶æ®µæ—¶é—´çº¿å¯è§†åŒ–")
        st.pyplot(fig)

    except Exception as e:
        st.error(f"âŒ æ— æ³•å¤„ç† Google Sheet æˆ–æ•°æ®æ ¼å¼å¼‚å¸¸ï¼š{e}")
